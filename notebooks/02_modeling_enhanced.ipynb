{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Player-Enhanced Features Experiment\n\n**Testing historical momentum + blowout + Haslametrics + player features**\n\nChanges from 02_modeling.ipynb:\n- ✅ Enhanced team stats (36 features vs 10 baseline)\n- ✅ Momentum features (win streak, recent form, avg margin)\n- ✅ Blowout tendency (large margin win/loss rates)\n- ✅ Haslametrics offensive efficiency\n- ✅ Team-specific home court advantage\n- ✅ **Player features (14 features):**\n  - Star player power (top 3 scorers PPG, efficiency)\n  - Offensive balance (scoring distribution)\n  - Bench depth (non-starter production)\n  - Key player efficiency (AST/TO, rebounds, usage)\n\nExpected: Test if player-based features improve MAE"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import our modules\nfrom src import config\nfrom src.elo import EloRatingSystem\nfrom src.models import ImprovedSpreadModel\nfrom src.utils import fetch_barttorvik_year\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_absolute_error\n\nprint(\"Libraries loaded!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Real Historical Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical game results\n",
    "games = pd.read_csv(config.HISTORICAL_GAMES_FILE, parse_dates=['date'])\n",
    "\n",
    "print(f\"Loaded {len(games)} real games\")\n",
    "print(f\"Date range: {games['date'].min()} to {games['date'].max()}\")\n",
    "print(f\"Seasons: {sorted(games['season'].unique())}\")\n",
    "print(f\"\\nGames per season:\")\n",
    "print(games['season'].value_counts().sort_index())\n",
    "print(f\"\\nMargin stats:\")\n",
    "print(f\"  Mean: {games['margin'].mean():.2f}\")\n",
    "print(f\"  Std: {games['margin'].std():.2f}\")\n",
    "print(f\"  Median: {games['margin'].median():.2f}\")\n",
    "\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Initialize and Process Elo Ratings Chronologically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elo system using config\n",
    "elo = EloRatingSystem(\n",
    "    k_factor=config.ELO_CONFIG['k_factor'],\n",
    "    hca=config.ELO_CONFIG['home_court_advantage'],\n",
    "    carryover=config.ELO_CONFIG['season_carryover']\n",
    ")\n",
    "\n",
    "# Load conference mappings from config\n",
    "elo.load_conference_mappings(config.CONFERENCE_MAPPINGS)\n",
    "\n",
    "print(\"Elo system initialized with conference mappings from config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process games chronologically to build Elo ratings\n",
    "print(\"Processing games chronologically to build Elo history...\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "elo_snapshots = elo.process_games(\n",
    "    games,\n",
    "    date_col='date',\n",
    "    home_col='home_team',\n",
    "    away_col='away_team',\n",
    "    home_score_col='home_score',\n",
    "    away_score_col='away_score',\n",
    "    neutral_col='neutral_site',\n",
    "    season_col='season',\n",
    "    save_snapshots=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Processed {len(elo_snapshots)} games\")\n",
    "print(f\"✓ Tracked {len(elo.ratings)} team Elo ratings\")\n",
    "\n",
    "# Display top teams\n",
    "print(\"\\nTop 15 teams by current Elo:\")\n",
    "elo.get_rankings(top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Merge Elo with Enhanced Team Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch team stats for training years using config and utils\n",
    "all_stats = []\n",
    "for year in config.TRAINING_YEARS:\n",
    "    print(f\"Fetching {year}...\")\n",
    "    df = fetch_barttorvik_year(year)\n",
    "    df['season'] = year\n",
    "    all_stats.append(df[['team', 'adjoe', 'adjde', 'season']])\n",
    "\n",
    "team_stats = pd.concat(all_stats, ignore_index=True)\n",
    "team_stats.columns = ['team', 'adj_oe', 'adj_de', 'season']\n",
    "team_stats['adj_em'] = team_stats['adj_oe'] - team_stats['adj_de']\n",
    "\n",
    "print(f\"\\nLoaded efficiency stats for {len(team_stats)} team-seasons\")\n",
    "team_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Create Training Features from Real Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Elo snapshots with team efficiency stats\n",
    "print(\"Creating training features from real game data...\")\n",
    "\n",
    "# Add efficiency stats to elo_snapshots based on team and date\n",
    "# Match by season (extract from date)\n",
    "elo_snapshots['season'] = elo_snapshots['date'].dt.year\n",
    "\n",
    "# Merge home team stats\n",
    "train_data = elo_snapshots.merge(\n",
    "    team_stats,\n",
    "    left_on=['home_team', 'season'],\n",
    "    right_on=['team', 'season'],\n",
    "    how='left',\n",
    "    suffixes=('', '_home')\n",
    ")\n",
    "train_data = train_data.rename(columns={'adj_oe': 'home_adj_oe', 'adj_de': 'home_adj_de', 'adj_em': 'home_adj_em'})\n",
    "train_data = train_data.drop(columns=['team'], errors='ignore')\n",
    "\n",
    "# Merge away team stats\n",
    "train_data = train_data.merge(\n",
    "    team_stats,\n",
    "    left_on=['away_team', 'season'],\n",
    "    right_on=['team', 'season'],\n",
    "    how='left',\n",
    "    suffixes=('', '_away')\n",
    ")\n",
    "train_data = train_data.rename(columns={'adj_oe': 'away_adj_oe', 'adj_de': 'away_adj_de', 'adj_em': 'away_adj_em'})\n",
    "train_data = train_data.drop(columns=['team'], errors='ignore')\n",
    "\n",
    "# Calculate derived features\n",
    "train_data['eff_diff'] = train_data['home_adj_em'] - train_data['away_adj_em']\n",
    "train_data['elo_diff'] = train_data['home_elo_before'] - train_data['away_elo_before']\n",
    "\n",
    "# Drop rows with missing efficiency data\n",
    "train_data = train_data.dropna(subset=['home_adj_oe', 'away_adj_oe'])\n",
    "\n",
    "print(f\"✓ Created {len(train_data)} training samples from real games\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print([c for c in train_data.columns if 'adj' in c or 'elo' in c or 'diff' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features using config\n",
    "feature_cols = config.BASELINE_FEATURES\n",
    "\n",
    "X = train_data[feature_cols]\n",
    "y = train_data['actual_margin']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"\\nTarget (actual_margin) stats:\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Std: {y.std():.2f}\")\n",
    "print(f\"  Median: {y.median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Train Model on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train improved model using config parameters\n",
    "print(\"Training ImprovedSpreadModel on REAL game data...\\n\")\n",
    "\n",
    "model = ImprovedSpreadModel(\n",
    "    ridge_alpha=config.MODEL_CONFIG['ridge_alpha'],\n",
    "    lgbm_params={\n",
    "        'n_estimators': config.MODEL_CONFIG['n_estimators'],\n",
    "        'max_depth': config.MODEL_CONFIG['max_depth'],\n",
    "        'learning_rate': config.MODEL_CONFIG['learning_rate'],\n",
    "    },\n",
    "    weights=(\n",
    "        config.MODEL_CONFIG['ridge_weight'],\n",
    "        config.MODEL_CONFIG['lgbm_weight']\n",
    "    ),\n",
    "    use_lgbm=True\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "print(\"✓ Model trained!\\n\")\n",
    "\n",
    "# Component performance\n",
    "components = model.predict_components(X)\n",
    "for name, preds in components.items():\n",
    "    mae = np.abs(preds - y).mean()\n",
    "    rmse = np.sqrt(((preds - y) ** 2).mean())\n",
    "    print(f\"{name:12} MAE={mae:.3f}, RMSE={rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on real data using config\n",
    "print(\"\\nRunning 5-fold time-series cross-validation...\\n\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=config.CV_CONFIG['n_splits'])\n",
    "cv_results = {'ridge': [], 'ensemble': []}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    fold_model = ImprovedSpreadModel(\n",
    "        ridge_alpha=config.MODEL_CONFIG['ridge_alpha'],\n",
    "        lgbm_params={\n",
    "            'n_estimators': config.MODEL_CONFIG['n_estimators'],\n",
    "            'max_depth': config.MODEL_CONFIG['max_depth'],\n",
    "            'learning_rate': config.MODEL_CONFIG['learning_rate'],\n",
    "        },\n",
    "        weights=(\n",
    "            config.MODEL_CONFIG['ridge_weight'],\n",
    "            config.MODEL_CONFIG['lgbm_weight']\n",
    "        )\n",
    "    )\n",
    "    fold_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = fold_model.predict(X_val)\n",
    "    components = fold_model.predict_components(X_val)\n",
    "    \n",
    "    ridge_mae = np.abs(components['ridge'] - y_val).mean()\n",
    "    ensemble_mae = np.abs(preds - y_val).mean()\n",
    "    \n",
    "    cv_results['ridge'].append(ridge_mae)\n",
    "    cv_results['ensemble'].append(ensemble_mae)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Ridge MAE={ridge_mae:.3f}, Ensemble MAE={ensemble_mae:.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Ridge CV MAE:    {np.mean(cv_results['ridge']):.3f} ± {np.std(cv_results['ridge']):.3f}\")\n",
    "print(f\"Ensemble CV MAE: {np.mean(cv_results['ensemble']):.3f} ± {np.std(cv_results['ensemble']):.3f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "## 6. Generate 2026 Predictions with Player-Enhanced Features"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# Load 2026 PLAYER-ENHANCED team stats and prediction template\nteam_stats_2026 = pd.read_csv(config.PROCESSED_DATA_DIR / 'team_stats_2025_26_player_enhanced.csv')\ntemplate = pd.read_csv(config.DATA_DIR.parent / config.SUBMISSION_TEMPLATE)\ntemplate = template.dropna(subset=['Home', 'Away'])\n\nprint(f\"Teams for 2026: {len(team_stats_2026)}\")\nprint(f\"Games to predict: {len(template)}\")\nprint(f\"\\nPlayer-enhanced features available ({len(team_stats_2026.columns)} total):\")\nprint(\"Baseline features (10): off_efficiency, def_efficiency, elo_rating, etc.\")\nprint(\"Historical features (11): win_streak, recent_form, avg_margin, blowout tendency\")\nprint(\"Haslametrics (2): haslametrics_off_eff, haslametrics_rank\")\nprint(\"Player features (14): star PPG, bench depth, offensive balance, efficiency\")\nprint(f\"\\nSample columns: {team_stats_2026.columns[:5].tolist()}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction features\n",
    "team_dict = team_stats_2026.set_index('team').to_dict('index')\n",
    "\n",
    "pred_features = []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, row in template.iterrows():\n",
    "    home = row['Home']\n",
    "    away = row['Away']\n",
    "    \n",
    "    if home not in team_dict or away not in team_dict:\n",
    "        continue\n",
    "    \n",
    "    home_stats = team_dict[home]\n",
    "    away_stats = team_dict[away]\n",
    "    \n",
    "    home_oe = home_stats.get('off_efficiency', 100)\n",
    "    home_de = home_stats.get('def_efficiency', 100)\n",
    "    away_oe = away_stats.get('off_efficiency', 100)\n",
    "    away_de = away_stats.get('def_efficiency', 100)\n",
    "    \n",
    "    features = {\n",
    "        'home_adj_oe': home_oe,\n",
    "        'home_adj_de': home_de,\n",
    "        'home_adj_em': home_oe - home_de,\n",
    "        'away_adj_oe': away_oe,\n",
    "        'away_adj_de': away_de,\n",
    "        'away_adj_em': away_oe - away_de,\n",
    "        'eff_diff': (home_oe - home_de) - (away_oe - away_de),\n",
    "        'home_elo_before': elo.get_rating(home),\n",
    "        'away_elo_before': elo.get_rating(away),\n",
    "        'elo_diff': elo.get_rating(home) - elo.get_rating(away),\n",
    "        'predicted_spread': elo.predict_spread(home, away),\n",
    "    }\n",
    "    \n",
    "    pred_features.append(features)\n",
    "    valid_indices.append(idx)\n",
    "\n",
    "X_pred = pd.DataFrame(pred_features)\n",
    "print(f\"✓ Created features for {len(X_pred)} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = model.predict(X_pred)\n",
    "components = model.predict_components(X_pred)\n",
    "\n",
    "results = template.copy()\n",
    "for i, idx in enumerate(valid_indices):\n",
    "    results.loc[idx, 'pt_spread'] = predictions[i]\n",
    "    results.loc[idx, 'ridge_pred'] = components['ridge'][i]\n",
    "    results.loc[idx, 'lgbm_pred'] = components['lgbm'][i]\n",
    "    results.loc[idx, 'elo_spread'] = X_pred.iloc[i]['predicted_spread']\n",
    "\n",
    "print(\"✓ Predictions generated!\")\n",
    "results[['Date', 'Away', 'Home', 'pt_spread', 'ridge_pred', 'lgbm_pred']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": "## 7. Save Player-Enhanced Predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare submission using config team info\nsubmission = results[['Date', 'Away', 'Home', 'pt_spread']].copy()\nsubmission = submission.dropna(subset=['pt_spread'])\n\nsubmission['team_name'] = ''\nsubmission['team_member'] = ''\nsubmission['team_email'] = ''\n\n# Use team info from config\nteam_members = config.TEAM_INFO['members']\nsubmission.loc[submission.index[0], 'team_name'] = config.TEAM_INFO['team_name']\nfor i, member in enumerate(team_members):\n    if i < len(submission):\n        submission.loc[submission.index[i], 'team_member'] = member['name']\n        submission.loc[submission.index[i], 'team_email'] = member['email']\n\n# Save to player-enhanced path for comparison\nplayer_enhanced_output = config.PREDICTIONS_DIR / 'tsa_pt_spread_CMMT_2026_player_enhanced.csv'\nsubmission.to_csv(player_enhanced_output, index=False)\nprint(f\"✓ Saved: {player_enhanced_output}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Final Summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"PLAYER-ENHANCED MODEL SUMMARY\")\nprint(\"=\"*60)\nprint(f\"Training: {len(train_data)} real games (2020-2025)\")\nprint(f\"Features: {len(feature_cols)} baseline features (for training)\")\nprint(f\"Predictions: {len(submission)} games\\n\")\nprint(f\"Cross-Validation Results:\")\nprint(f\"  Ridge MAE:    {np.mean(cv_results['ridge']):.3f} ± {np.std(cv_results['ridge']):.3f}\")\nprint(f\"  Ensemble MAE: {np.mean(cv_results['ensemble']):.3f} ± {np.std(cv_results['ensemble']):.3f}\")\nprint(\"\\nNote: Player-enhanced features (36 total) only used in 2026 team stats:\")\nprint(\"      - 10 baseline (off/def efficiency, elo)\")\nprint(\"      - 11 historical (momentum, blowout tendency)\")\nprint(\"      - 2 Haslametrics (offensive efficiency, rank)\")\nprint(\"      - 14 player (star power, bench depth, balance, efficiency)\")\nprint(\"      Training data still uses baseline features only.\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": "## 8. Compare Baseline vs Player-Enhanced Predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "# Load baseline predictions for comparison\nbaseline_pred = pd.read_csv(config.PREDICTION_OUTPUT_FILE)\nplayer_enhanced_pred = pd.read_csv(player_enhanced_output)\n\n# Compare predictions\ncomparison = baseline_pred[['Date', 'Away', 'Home', 'pt_spread']].copy()\ncomparison = comparison.rename(columns={'pt_spread': 'baseline_spread'})\ncomparison = comparison.merge(\n    player_enhanced_pred[['Date', 'Away', 'Home', 'pt_spread']],\n    on=['Date', 'Away', 'Home'],\n    how='inner'\n)\ncomparison = comparison.rename(columns={'pt_spread': 'player_enhanced_spread'})\ncomparison['difference'] = comparison['player_enhanced_spread'] - comparison['baseline_spread']\n\nprint(f\"Comparing {len(comparison)} predictions:\\n\")\nprint(f\"Mean difference: {comparison['difference'].mean():.3f}\")\nprint(f\"Std difference:  {comparison['difference'].std():.3f}\")\nprint(f\"Max difference:  {comparison['difference'].abs().max():.3f}\")\nprint(f\"\\nTop 10 games with biggest prediction changes:\")\ncomparison.nlargest(10, 'difference')[['Date', 'Away', 'Home', 'baseline_spread', 'player_enhanced_spread', 'difference']]"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}