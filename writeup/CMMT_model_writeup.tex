\documentclass[10pt]{article}

\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}

% Compact list settings
\setlist[itemize]{noitemsep,topsep=2pt,leftmargin=14pt}
\setlist[enumerate]{noitemsep,topsep=2pt,leftmargin=14pt}

% Table compactness
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.15}

\title{\vspace{-1.5cm}\textbf{NCAA Basketball Point Spread Prediction Model}}
\author{Team CMMT: Caleb Han, Mason Mines, Mason Wang, Tony Wang}
\date{}

\begin{document}
\pagenumbering{gobble} % Remove page numbers
\maketitle
\vspace{-0.8cm}

\section*{Model Architecture}
We developed an ensemble model combining Ridge Regression (30\%) and LightGBM (70\%) to predict point spreads:
\[
\text{Predicted Spread} = 0.3 \times \text{Ridge}_{\text{pred}} + 0.7 \times \text{LightGBM}_{\text{pred}}.
\]
Ridge provides a stable, interpretable linear baseline, while LightGBM captures complex non-linear patterns. The ensemble balances model transparency with predictive accuracy.

\section*{Data Sources \& Features}
Our model uses \textbf{11 features} derived from two primary data sources:
\begin{itemize}
    \item \textbf{Barttorvik efficiency ratings}\footnote{\href{https://barttorvik.com}{barttorvik.com}}: Adjusted Offensive/Defensive Efficiency (AdjOE/AdjDE), measured as points per 100 possessions and adjusted for opponent strength. Efficiency Margin (AdjEM) = AdjOE$-$AdjDE.
    \item \textbf{Elo ratings}\footnote{\href{https://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/}{fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/}}: FiveThirtyEight-style Elo with K-factor = 38, home-court advantage = 4.0 points, and 64\% season carryover to conference average.
\end{itemize}

\noindent\textbf{Complete feature set (11):}
\begin{itemize}
    \item \textbf{Team efficiencies (6)}: home/away AdjOE, AdjDE, AdjEM.
    \item \textbf{Elo features (3)}: home/away Elo, Elo differential.
    \item \textbf{Derived features (2)}: efficiency differential, Elo-based spread.
\end{itemize}

\section*{Training Data}
Trained on \textbf{18,024 NCAA games} from 2020--2025 (6 seasons), representing 53.4\% of games after filtering for complete Barttorvik data. Games processed chronologically for accurate Elo histories and to avoid data leakage.

\section*{Model Evaluation}
We used \textbf{5-fold time-series cross-validation} to respect temporal ordering, evaluating on future games to mimic real-world prediction.

\noindent\textbf{Performance metrics:}
\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{MAE (points)} & \textbf{RMSE (points)} \\
\midrule
Ridge & 5.975 $\pm$ 0.160 & 7.85 \\
LightGBM & 4.65 $\pm$ 0.29 & 6.22 \\
\textbf{Ensemble} & \textbf{5.171 $\pm$ 0.248} & \textbf{6.89} \\
\bottomrule
\end{tabular}
\end{center}

\noindent The ensemble achieves MAE of \textbf{5.2 points} with lower variance, demonstrating improved robustness.

\section*{Key Decisions}
\vspace{-0.1cm}
\begin{itemize}
    \item \textbf{Feature selection:} Retained 11 baseline features (efficiency + Elo). Advanced features decreased performance. AdjOE/AdjDE and Elo differential were strongest predictors.
    \item \textbf{Data quality:} Comprehensive validation ensures correct team-stat alignment.
    \item \textbf{Ensemble weighting:} LightGBM 70\%, Ridge 30\%. Optimized via validation.
    \item \textbf{Hyperparameters:} Ridge $\alpha$ = 1.0; LightGBM: 100 trees, depth = 8, rate = 0.1.
\end{itemize}

\vfill
\begin{center}
{\small Code: \href{https://github.com/calebyhan/triangle-sports-analytics-26}{github.com/calebyhan/triangle-sports-analytics-26}}
\end{center}

\end{document}
